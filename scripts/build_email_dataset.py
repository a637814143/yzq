# -*- coding: utf-8 -*-
"""
build_email_dataset.py
- ä» data ç›®å½•ï¼ˆå«å¤šçº§å­ç›®å½•ã€æ–‡ä»¶æ— æ‰©å±•åï¼‰æ‰¹é‡æå–é‚®ä»¶ç‰¹å¾
- æ ‡ç­¾æ¥è‡ª TREC06C çš„ index æ–‡ä»¶ï¼ˆå¦‚ï¼š'ham ../data/000/001'ï¼‰
- ä¸¥æ ¼ä½¿ç”¨ spam->1, ham->0
- è¾“å‡ºæ—¶ä¸åŒ…å« path å­—æ®µ
"""

import os, sys, json, glob
from pathlib import Path
from typing import Dict, Any, List, Tuple

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¿è¯èƒ½ import åˆ°æœ¬åŒ…
_THIS = Path(__file__).resolve()
_ROOT = _THIS.parent.parent
if str(_ROOT) not in sys.path:
    sys.path.insert(0, str(_ROOT))

from email_feature_engine import parse_eml, extract_text_features, vectorize_feature_list  # ä½ å·²æœ‰çš„æ¨¡å—
import numpy as np

try:
    from tqdm import tqdm
except Exception:
    def tqdm(x): return x

# =================== é…ç½®åŒº ===================
# é‚®ä»¶æ‰€åœ¨æ ¹ç›®å½•ï¼ˆä½ çš„ data æ ¹ï¼‰
INPUT_DIR    = r"E:\æ¯•ä¸šè®¾è®¡\trec06c\data"
# TREC06C çš„ index æ–‡ä»¶ï¼ˆæ— æ‰©å±•åä¹Ÿå¯ï¼‰
LABEL_FILE   = r"E:\æ¯•ä¸šè®¾è®¡\trec06c\full\index"

# è¾“å‡º
OUTPUT_JSONL = r"E:\æ¯•ä¸šè®¾è®¡\æ–°æµ‹è¯•\email_features.jsonl"
OUTPUT_NPY   = r"E:\æ¯•ä¸šè®¾è®¡\æ–°æµ‹è¯•\email_features.npy"
BUCKET_SIZE  = 1024

# æ‰«ææ˜¯å¦é€’å½’
RECURSIVE    = True
# =============================================

def _norm_path(p: str) -> str:
    """ç»Ÿä¸€è·¯å¾„ï¼šå»å¼•å·ã€åæ–œæ è½¬æ–œæ ã€å°å†™ã€‚"""
    p = (p or "").strip().strip('"').strip("'")
    return p.replace("\\", "/").lower()

def _abs_and_rel_keys(p_abs: Path, root_abs: Path) -> Tuple[str, str]:
    """è¿”å›è§„èŒƒåŒ–åçš„ç»å¯¹è·¯å¾„é”®ä¸â€œç›¸å¯¹ root çš„ç›¸å¯¹é”®â€"""
    abs_k = _norm_path(str(p_abs))
    try:
        rel_k = _norm_path(str(p_abs.relative_to(root_abs)))
    except Exception:
        # ä¸åœ¨æ ¹ç›®å½•ä¸‹å°±é€€åŒ–ä¸ºæ–‡ä»¶å
        rel_k = _norm_path(p_abs.name)
    return abs_k, rel_k

def load_labels_from_trec_index(index_file: str, dataset_root: str) -> Dict[str, Any]:
    """
    è¯»å– TREC06C indexï¼š
        ham ../data/000/001
        spam ../data/000/002
    å¹¶å»ºç«‹ä¸¤å¥—é”®ï¼šç»å¯¹è·¯å¾„é”®ã€ç›¸å¯¹ INPUT_DIR é”®
    """
    by_path: Dict[str, int] = {}

    idx_path = Path(index_file).resolve()
    base_for_rel = idx_path.parent  # ä»¥ index æ‰€åœ¨ç›®å½•ä¸ºç›¸å¯¹è·¯å¾„åŸºå‡†
    root_abs = Path(dataset_root).resolve()

    spam_map = {"spam": 1, "ham": 0, "1": 1, "0": 0}

    with open(idx_path, "r", encoding="utf-8", errors="ignore") as f:
        for ln, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) < 2:
                continue
            raw_label, rel_path = parts[0], " ".join(parts[1:])

            raw_label_l = raw_label.lower()
            if raw_label_l not in spam_map:
                # æ—¢ä¸æ˜¯ spam/ham ä¹Ÿä¸æ˜¯ 1/0ï¼Œè·³è¿‡
                continue
            lab = spam_map[raw_label_l]

            # ç”¨ index çš„ç›®å½•ä½œä¸ºç›¸å¯¹è·¯å¾„åŸºå‡†æ¥è§£æ
            p_abs = (base_for_rel / rel_path).resolve()

            # å»ºç«‹ä¸¤ä¸ª keyï¼šç»å¯¹ä¸ç›¸å¯¹ï¼ˆç›¸å¯¹äº INPUT_DIRï¼‰
            abs_k, rel_k = _abs_and_rel_keys(p_abs, root_abs)
            by_path[abs_k] = lab
            by_path[rel_k] = lab

            # å†è¡¥å……ä¸€ä¸ªä»…æ–‡ä»¶åé”®ï¼Œé˜²æ­¢æç«¯åœºæ™¯ï¼ˆå¯é€‰ï¼‰
            by_path[_norm_path(p_abs.name)] = lab

    return {"by_path": by_path}

def iter_mail_files(root_dir: str, recursive: bool = True) -> List[str]:
    """
    é€’å½’æ”¶é›†â€œçœŸå®æ–‡ä»¶â€ï¼ˆæ— æ‰©å±•åä¹Ÿè¡Œï¼‰ï¼Œè¿‡æ»¤æ‰ç›®å½•ã€‚
    """
    root = Path(root_dir).resolve()
    # '**/*' ä¼šæŠŠæ–‡ä»¶å’Œç›®å½•éƒ½åˆ—å‡ºæ¥ï¼Œåé¢è¦è¿‡æ»¤æ‰ç›®å½•
    pats = ["**/*"] if recursive else ["*"]
    files: List[str] = []
    for pat in pats:
        for p in root.glob(pat):
            if p.is_file():
                files.append(str(p))
    return files

def main():
    # åŸºæœ¬è·¯å¾„æ£€æŸ¥
    in_root = Path(INPUT_DIR).resolve()
    if not in_root.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥ç›®å½•ï¼š{INPUT_DIR}")

    # è¾“å‡ºç›®å½•å‡†å¤‡
    for out in (OUTPUT_JSONL, OUTPUT_NPY):
        if out:
            Path(out).parent.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ ‡ç­¾
    label_map = load_labels_from_trec_index(LABEL_FILE, dataset_root=str(in_root))
    by_path = label_map["by_path"]
    print(f"âœ… æ ‡ç­¾åŠ è½½ï¼šè·¯å¾„æ˜ å°„ {len(by_path)} æ¡ï¼ˆspamâ†’1, hamâ†’0ï¼‰")

    # æ‰«ææ–‡ä»¶
    files = iter_mail_files(str(in_root), RECURSIVE)
    print(f"ğŸ“‚ æ‰«æç›®å½•: {in_root} (é€’å½’={RECURSIVE})ï¼Œå‘ç°æ–‡ä»¶æ•°ï¼š{len(files)}")

    if not files:
        print("â— æœªå‘ç°å¯è§£æçš„é‚®ä»¶æ–‡ä»¶ï¼Œé€€å‡ºã€‚")
        return

    feats = []
    miss, ok = 0, 0
    outf = open(OUTPUT_JSONL, "w", encoding="utf-8") if OUTPUT_JSONL else None

    for p in tqdm(files):
        try:
            # è·³è¿‡ä¸å¯è¯»æˆ–å¤§å°ä¸º 0 çš„æ–‡ä»¶
            try:
                if os.path.getsize(p) == 0:
                    continue
            except Exception:
                pass

            parsed = parse_eml(p)  # ä½ ç°æœ‰çš„è§£æå‡½æ•°ï¼ˆæ”¯æŒæ— æ‰©å±•åï¼‰

            # â€”â€” æ ‡ç­¾å¯¹é½ï¼šç»å¯¹/ç›¸å¯¹ ä¸¤å¥—é”®éƒ½å°è¯• â€”â€” #
            p_abs = Path(p).resolve()
            abs_k, rel_k = _abs_and_rel_keys(p_abs, in_root)

            label = None
            if abs_k in by_path:
                label = by_path[abs_k]
            elif rel_k in by_path:
                label = by_path[rel_k]
            else:
                # å†è¯•æ–‡ä»¶åé”®ï¼ˆå…œåº•ï¼‰
                label = by_path.get(_norm_path(p_abs.name))

            feat = extract_text_features(parsed)  # ç”Ÿæˆç‰¹å¾å­—å…¸

            # â€”â€” æŒ‰éœ€ç§»é™¤ path å­—æ®µ â€”â€” #
            if "path" in feat:
                del feat["path"]

            # å†™å…¥æ ‡ç­¾ï¼ˆæœªå‘½ä¸­åˆ™ -1ï¼Œä¾¿äºä½ åç»­ç»Ÿè®¡ï¼‰
            feat["label"] = int(label) if label is not None else -1

            if label is None:
                miss += 1
            else:
                ok += 1

            feats.append(feat)
            if outf:
                outf.write(json.dumps(feat, ensure_ascii=False) + "\n")

        except Exception as e:
            # è§£æå¤±è´¥ä¹Ÿå†™ä¸€è¡Œé”™è¯¯ä¿¡æ¯ï¼ˆä¸å« pathï¼‰
            if outf:
                outf.write(json.dumps({"error": f"parse_failed: {e}"}, ensure_ascii=False) + "\n")

    if outf:
        outf.close()
        print(f"ğŸ“ å·²å†™å…¥ç‰¹å¾ï¼š{OUTPUT_JSONL}ï¼ˆæœ‰æ•ˆ {ok} æ¡ï¼ŒæœªåŒ¹é…æ ‡ç­¾ {miss} æ¡ï¼Œå«é”™è¯¯è¡Œå·²è®°å½•ï¼‰")

    # å‘é‡åŒ–ï¼ˆä»…å½“å­˜åœ¨æœ‰æ•ˆæ ·æœ¬ï¼‰
    valid = [x for x in feats if "subject_len" in x]
    if not valid:
        print("â— æ²¡æœ‰å¯å‘é‡åŒ–çš„æœ‰æ•ˆç‰¹å¾ï¼Œè·³è¿‡ã€‚")
        return

    if OUTPUT_NPY:
        X, header = vectorize_feature_list(valid, bucket_size=BUCKET_SIZE)
        np.save(OUTPUT_NPY, X)
        print(f"ğŸ”¢ å·²ä¿å­˜å‘é‡ï¼š{OUTPUT_NPY}ï¼Œshape={X.shape}")

if __name__ == "__main__":
    main()
